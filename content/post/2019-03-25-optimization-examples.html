---
title: 'Optimization Examples in R'
author: 'Roger J. Bos, CFA'
date: '2019-01-16'
slug: Optimization-Examples-in-R
description: 'Optimization examples in R'
output: 
  html_document:
    number_sections: TRUE
    
---



<div id="prerequisites" class="section level1">
<h1>Prerequisites</h1>
<p>Before we get to the optimization examples, we will download the price history for a small number of ETFs and show how to calculate the returns, standard deviations, variance matrix and other inputs that we will need for the optimizer.</p>
<div id="prices" class="section level2">
<h2>Prices</h2>
<p>For these examples, we will download the daily prices for a handful of ETFs from Yahoo Finance, starting in 2003. Once the daily data is downloaded, we use the <em>to.weekly()</em> function to convert the prices to a weekly series (there is also a <em>to.monthly()</em> function) and then combine the series column by column into a data.frame.</p>
<pre class="r"><code>library(xts)
library(quantmod)</code></pre>
<pre><code>## Loading required package: TTR</code></pre>
<pre><code>## Registered S3 method overwritten by &#39;quantmod&#39;:
##   method            from
##   as.zoo.data.frame zoo</code></pre>
<pre><code>## Version 0.4-0 included new data defaults. See ?getSymbols.</code></pre>
<pre class="r"><code>library(ggplot2)</code></pre>
<pre><code>## 
## Attaching package: &#39;ggplot2&#39;</code></pre>
<pre><code>## The following object is masked _by_ &#39;.GlobalEnv&#39;:
## 
##     %+%</code></pre>
<pre class="r"><code>symbols &lt;- c(&quot;IWD&quot;,&quot;IWF&quot;,&quot;IWN&quot;,&quot;IWO&quot;,&quot;IWP&quot;,&quot;IWS&quot;)
initDate &lt;- &quot;2003-01-01&quot;
go &lt;- try(getSymbols(symbols, from = initDate))</code></pre>
<pre><code>## pausing 1 second between requests for more than 5 symbols</code></pre>
<pre><code>## pausing 1 second between requests for more than 5 symbols</code></pre>
<pre class="r"><code>prices &lt;- list()
for(i in 1:length(symbols)) {
  tmp &lt;- Ad(get(symbols[i]))
  tmp &lt;- to.weekly(tmp, indexat=&quot;%m/%d/%Y&quot;)
  tmp &lt;- tmp$tmp.Close
  names(tmp) &lt;- symbols[i]
  prices[[i]] &lt;- tmp
}
prices &lt;- do.call(cbind, prices)
tail(prices)</code></pre>
<pre><code>##                 IWD      IWF      IWN      IWO      IWP      IWS
## 2019-11-22 132.1258 168.3194 122.4054 203.4633 148.5290 91.25584
## 2019-11-29 132.9388 170.9825 124.3332 209.4792 150.7850 92.01132
## 2019-12-06 133.5238 170.6035 125.4263 210.6465 150.0363 92.32943
## 2019-12-13 134.3170 171.9300 126.1020 210.4370 150.2360 92.73700
## 2019-12-20 136.3200 175.2100 128.6700 214.7500 152.8900 94.52000
## 2019-12-24 136.3300 175.5700 128.8700 216.1900 153.0200 94.48000</code></pre>
</div>
<div id="returns" class="section level2">
<h2>Returns</h2>
<p>Once we have the prices, we can use the <em>lag.xts</em> function to calculate the (weekly) returns. Note the explicit call to <em>lag.xts</em> instead of just <em>lag</em>. A number of different packages have a <em>lag</em> function and they do not all work the same, so it is better to be safe here and explicitly call the one we want to use. We also create a log prices series just for good measure.</p>
<pre class="r"><code>prices &lt;- as.xts(prices)
returns &lt;- (prices / lag.xts(prices, k = 1) - 1)
returns[is.na(returns)] &lt;- 0
logprices &lt;- log(prices)
tail(logprices)</code></pre>
<pre><code>##                 IWD      IWF      IWN      IWO      IWP      IWS
## 2019-11-22 4.883755 5.125864 4.807338 5.315486 5.000780 4.513667
## 2019-11-29 4.889889 5.141561 4.822965 5.344625 5.015855 4.521912
## 2019-12-06 4.894280 5.139342 4.831718 5.350181 5.010878 4.525363
## 2019-12-13 4.900203 5.147087 4.837091 5.349186 5.012207 4.529768
## 2019-12-20 4.915005 5.165985 4.857251 5.369475 5.029719 4.548811
## 2019-12-24 4.915078 5.168038 4.858804 5.376158 5.030569 4.548388</code></pre>
<pre class="r"><code>tail(returns)</code></pre>
<pre><code>##                       IWD          IWF          IWN           IWO           IWP
## 2019-11-22 -0.00261951840 -0.002010725 -0.010284414  0.0005886833  0.0026955567
## 2019-11-29  0.00615337008  0.015821256  0.015749330  0.0295675634  0.0151892366
## 2019-12-06  0.00440033968 -0.002216590  0.008791522  0.0055721605 -0.0049652673
## 2019-12-13  0.00594049133  0.007775563  0.005387452 -0.0009945762  0.0013306509
## 2019-12-20  0.01491252771  0.019077525  0.020364411  0.0204954646  0.0176655871
## 2019-12-24  0.00007332013  0.002054677  0.001554341  0.0067054808  0.0008503172
##                      IWS
## 2019-11-22 -0.0055248308
## 2019-11-29  0.0082787692
## 2019-12-06  0.0034572702
## 2019-12-13  0.0044143021
## 2019-12-20  0.0192263821
## 2019-12-24 -0.0004231274</code></pre>
</div>
<div id="expected-returns-and-standard-deviation" class="section level2">
<h2>Expected returns and Standard Deviation</h2>
<p>The Greek letter <span class="math inline">\(\mu\)</span> (mu) is usually used to represent the expected return. Often we donâ€™t have an actual forecast of the return, so we use the naive forecast, which is the historical mean return. The mean return can be easily calculated in R using the apply function on the second dimension (the columns) using the <em>mean</em> function. If one or more observations are NA then the mean function will return NA unless you tell it to remove NAs by setting na.rm = TRUE. Likewise, you can use apply with the standard deviation (sd) function, which is usually represented with the Greek letter <span class="math inline">\(\sigma\)</span>.</p>
<p>The standard deviation of returns is by far the most widely used measure of risk, but there are other options. One option is the downside deviation. Recall the formula for standard deviation is <span class="math inline">\(\sqrt\sum(x-\overline{x})^{2}\)</span>. The downside deviation calculation focuses only on the cases where <span class="math inline">\(x \lt \overline{x}\)</span>. The rational given for this is that it is the negative deviations in returns that are problematic. No on complains about large positive deviations, unless of course, you are short the stock, in which case you could use the upside deviation calculation. For the vast majority of stocks all the deviation calculations are very similar and as stated before, it is probably best to stick to the the regular standard deviation calculation.</p>
<pre class="r"><code>mu &lt;- apply(returns, MARGIN=2, FUN=mean, na.rm=TRUE)
sigma &lt;- apply(returns, MARGIN=2, FUN=sd)
sigma2 &lt;- sqrt(apply(returns, MARGIN=2, FUN=var))
library(magrittr)</code></pre>
<pre><code>## 
## Attaching package: &#39;magrittr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:testthat&#39;:
## 
##     equals, is_less_than, not</code></pre>
<pre class="r"><code>sigma3 &lt;- apply(returns, MARGIN=2, FUN=var) %&gt;% sqrt()
rbind(sigma, sigma2, sigma3)</code></pre>
<pre><code>##               IWD        IWF        IWN        IWO       IWP        IWS
## sigma  0.02390707 0.02259287 0.02907531 0.03024997 0.0261257 0.02527248
## sigma2 0.02390707 0.02259287 0.02907531 0.03024997 0.0261257 0.02527248
## sigma3 0.02390707 0.02259287 0.02907531 0.03024997 0.0261257 0.02527248</code></pre>
<p>We show three different ways to calculate the same standard deviation above. The third one is essentially the same as the second, we just use the magrittr package in R which gives us the <em>%&gt;%</em> operator that makes the code easier to read. We will show you a fourth way to calculate standard deviation in the next section.</p>
<p>```</p>
</div>
<div id="variance-matrix" class="section level2">
<h2>Variance Matrix</h2>
<p>There are a couple of different ways to calculate the variance matrix (V). The simplest method is the esimate the sample covariance matrix.</p>
<pre class="r"><code>V &lt;- cov(returns, use=&quot;complete&quot;)
V</code></pre>
<pre><code>##              IWD          IWF          IWN          IWO          IWP
## IWD 0.0005715482 0.0004990278 0.0006290360 0.0006308704 0.0005707570
## IWF 0.0004990278 0.0005104376 0.0005741812 0.0006256150 0.0005680478
## IWN 0.0006290360 0.0005741812 0.0008453734 0.0008344155 0.0006924434
## IWO 0.0006308704 0.0006256150 0.0008344155 0.0009150609 0.0007499392
## IWP 0.0005707570 0.0005680478 0.0006924434 0.0007499392 0.0006825524
## IWS 0.0005858451 0.0005269485 0.0006922632 0.0006936184 0.0006259246
##              IWS
## IWD 0.0005858451
## IWF 0.0005269485
## IWN 0.0006922632
## IWO 0.0006936184
## IWP 0.0006259246
## IWS 0.0006386982</code></pre>
<pre class="r"><code>sigma4 &lt;- sqrt(diag(V))
sigma4</code></pre>
<pre><code>##        IWD        IWF        IWN        IWO        IWP        IWS 
## 0.02390707 0.02259287 0.02907531 0.03024997 0.02612570 0.02527248</code></pre>
<p>The <em>cov</em> function calculations the co-variance of the returns between each pair of stocks using the formula <span class="math inline">\(\sqrt\sum((x-\overline{x})(y-\overline{y})}\)</span>. On the diagonal of the matrix <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are the same and the resulting calculation is the variance, so that is why <span class="math inline">\(\sqrt(diag(V))\)</span> produces the standard deviation, which you can verify matches the prior methods of calculating standard deviation.</p>
</div>
<div id="robust-methods-of-handling-outliers" class="section level2">
<h2>Robust methods of handling outliers</h2>
<p>To simulate an outlier, we will create a second returns series with only one observation different, but the difference being very large (an outlier).</p>
<pre class="r"><code>returns2 &lt;- returns
returns2[60,2]</code></pre>
<pre><code>##                      IWF
## 2004-02-20 -0.0002068797</code></pre>
<pre class="r"><code>returns2[60,2] &lt;- 5</code></pre>
<p>Graphically, we can see how changing just one observation changes the correlation relationship of that ETF with the other ETFs.</p>
<pre class="r"><code>par(mfrow=c(1,2))
plot(as.dendrogram( hclust(
    as.dist(sqrt(2-cor(returns, use=&quot;complete&quot;)))
  ), h = .1 ), horiz = TRUE, xlim = c(1.3, 1)
)
plot(as.dendrogram( hclust(
    as.dist(sqrt(2-cor(returns2, use=&quot;complete&quot;)))
  ), h = .1 ), horiz = TRUE, xlim = c(1.3, 1)
)</code></pre>
<p><img src="/post/2019-03-25-optimization-examples_files/figure-html/dendrogram-1.png" width="672" /></p>
<pre class="r"><code>V &lt;- cov(returns, use=&quot;pairwise&quot;)
V2 &lt;- cov(returns2, use=&quot;pairwise&quot;)
print(V[1:3, 1:3])</code></pre>
<pre><code>##              IWD          IWF          IWN
## IWD 0.0005715482 0.0004990278 0.0006290360
## IWF 0.0004990278 0.0005104376 0.0005741812
## IWN 0.0006290360 0.0005741812 0.0008453734</code></pre>
<pre class="r"><code>print(V2[1:3, 1:3])</code></pre>
<pre><code>##              IWD          IWF          IWN
## IWD 0.0005715482 0.0004731283 0.0006290360
## IWF 0.0004731283 0.0286700968 0.0005220034
## IWN 0.0006290360 0.0005220034 0.0008453734</code></pre>
<p>R package <em>corpcor</em> has a function called <em>cov.shrink</em> that shrinks all of the covariances closer to the mean, based on a <em>lambda.var</em> parameter. Using <em>lambda.var</em> of zero returns the (unshrunk) sample covariance matrix and we verify that below. If <em>lambda.var</em> is not specified it is automatically determined. You can see that the shrunk covariance matrix does a good job of minimizing the effect of the outlier.</p>
<pre class="r"><code>library(corpcor)
V2.sample &lt;- cov.shrink(returns2, lambda.var = 0)</code></pre>
<pre><code>## Specified shrinkage intensity lambda.var (variance vector): 0 
## 
## Estimating optimal shrinkage intensity lambda (correlation matrix): 0.0099</code></pre>
<pre class="r"><code>V2.shrink &lt;- cov.shrink(returns2)</code></pre>
<pre><code>## Estimating optimal shrinkage intensity lambda.var (variance vector): 1 
## 
## Estimating optimal shrinkage intensity lambda (correlation matrix): 0.0099</code></pre>
<pre class="r"><code>print(V2[1:3, 1:3])</code></pre>
<pre><code>##              IWD          IWF          IWN
## IWD 0.0005715482 0.0004731283 0.0006290360
## IWF 0.0004731283 0.0286700968 0.0005220034
## IWN 0.0006290360 0.0005220034 0.0008453734</code></pre>
<pre class="r"><code>print(V2.sample[1:3, 1:3])</code></pre>
<pre><code>##              IWD          IWF          IWN
## IWD 0.0005715482 0.0004684639 0.0006228345
## IWF 0.0004684639 0.0286700968 0.0005168572
## IWN 0.0006228345 0.0005168572 0.0008453734</code></pre>
<pre class="r"><code>print(V2.shrink[1:3, 1:3])</code></pre>
<pre><code>##               IWD           IWF           IWN
## IWD 0.00076396292 0.00008841123 0.00068453277
## IWF 0.00008841123 0.00076396292 0.00008020547
## IWN 0.00068453277 0.00008020547 0.00076396292</code></pre>
<pre class="r"><code>print(V[1:3, 1:3])</code></pre>
<pre><code>##              IWD          IWF          IWN
## IWD 0.0005715482 0.0004990278 0.0006290360
## IWF 0.0004990278 0.0005104376 0.0005741812
## IWN 0.0006290360 0.0005741812 0.0008453734</code></pre>
<pre class="r"><code># create exponential weights for a weighted covariance matrix
wgts &lt;- .98^(nrow(returns):1)
V.weighted &lt;- cov.shrink(returns, w=wgts)</code></pre>
<pre><code>## Estimating optimal shrinkage intensity lambda.var (variance vector): 0.7345 
## 
## Estimating optimal shrinkage intensity lambda (correlation matrix): 0.0458</code></pre>
<pre class="r"><code>returns2 &lt;- returns
returns2[60,2] &lt;- -100

V2 &lt;- cov(returns2, use=&quot;pairwise&quot;)
dim(V2)</code></pre>
<pre><code>## [1] 6 6</code></pre>
<pre class="r"><code>dim(V2.shrink)</code></pre>
<pre><code>## [1] 6 6</code></pre>
<pre class="r"><code>V2.shrink &lt;- cov.shrink(returns2, lambda = 0.99)</code></pre>
<pre><code>## Estimating optimal shrinkage intensity lambda.var (variance vector): 0.9978 
## 
## Specified shrinkage intensity lambda (correlation matrix): 0.99</code></pre>
<pre class="r"><code>V2</code></pre>
<pre><code>##              IWD          IWF          IWN          IWO          IWP
## IWD 0.0005715482  0.001016994 0.0006290360 0.0006308704 0.0005707570
## IWF 0.0010169944 11.274972247 0.0016176913 0.0018428584 0.0008905030
## IWN 0.0006290360  0.001617691 0.0008453734 0.0008344155 0.0006924434
## IWO 0.0006308704  0.001842858 0.0008344155 0.0009150609 0.0007499392
## IWP 0.0005707570  0.000890503 0.0006924434 0.0007499392 0.0006825524
## IWS 0.0005858451  0.001192639 0.0006922632 0.0006936184 0.0006259246
##              IWS
## IWD 0.0005858451
## IWF 0.0011926390
## IWN 0.0006922632
## IWO 0.0006936184
## IWP 0.0006259246
## IWS 0.0006386982</code></pre>
<pre class="r"><code>V2[1:3, 1:3]</code></pre>
<pre><code>##              IWD          IWF          IWN
## IWD 0.0005715482  0.001016994 0.0006290360
## IWF 0.0010169944 11.274972247 0.0016176913
## IWN 0.0006290360  0.001617691 0.0008453734</code></pre>
<pre class="r"><code>V2.shrink[1:3, 1:3]</code></pre>
<pre><code>##                 IWD             IWF             IWN
## IWD 0.0007635374344 0.0000005611381 0.0000069123741
## IWF 0.0000005611381 0.0256945091749 0.0000007342114
## IWN 0.0000069123741 0.0000007342114 0.0007641429414</code></pre>
<pre class="r"><code>library(ellipse)</code></pre>
<pre><code>## 
## Attaching package: &#39;ellipse&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:graphics&#39;:
## 
##     pairs</code></pre>
<pre class="r"><code>plotcorr(cov2cor(V))</code></pre>
<p><img src="/post/2019-03-25-optimization-examples_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
</div>
<div id="risk-and-expected-returns" class="section level2">
<h2>Risk and Expected returns</h2>
<p><span class="math inline">\(\mu\)</span> is supposed to be the expected return. Often we donâ€™t have any actual forcast of the return, so we use the naive forecast, which is the mean return. The mean return can be easily calculated in R using the apply function on the second dimension (the columns) using the <em>mean</em> function. If one or more observations are NA then the mean function will return NA unless you tell it to remove NAs by setting na.rm = TRUE.</p>
<pre class="r"><code>mu &lt;- apply(returns, MARGIN=2, FUN=mean, na.rm=TRUE)</code></pre>
<p>and <span class="math inline">\(\sigma\)</span> (sigma) is the standard deviation (the square root of the variance).</p>
<pre class="r"><code>sigma2 &lt;- apply(returns, 2, sd)
sigma &lt;- sqrt(diag(V))</code></pre>
<pre class="r"><code>plot_assets &lt;- function(V, mu) {
  rd &lt;- data.frame(mu=mu, sigma=sqrt(diag(V)))
  rd$assets &lt;- row.names(rd)
  
  ggplot(rd, aes(x = sigma, y = mu, color = assets)) +
    geom_point(size = 2) +
    ylab(&quot;Expected Return&quot;) +
    xlab(&quot;Standard Deviation (Risk)&quot;) +
    xlim(0, max(sigma)) + 
    ylim(0, 1.2*max(mu)) +
    ggtitle(&quot;Expected Returns versus Risk&quot;)
    
}
  
plot_assets(V, mu)</code></pre>
<p><img src="/post/2019-03-25-optimization-examples_files/figure-html/plot_assets-1.png" width="672" /></p>
</div>
</div>
<div id="optimization" class="section level1">
<h1>Optimization</h1>
<p>There are many optimization packages available for R. To start off, we will use the <em>solve.QP</em> package, then move on to show some other optimizers.</p>
<div id="equal-weighted" class="section level2">
<h2>Equal-weighted</h2>
<p>The portfolio optimization problem is the problem of finding the optimal weights of a portfolio. For example, how much you should invest in each asset to maximize some desirable quantity, say risk-adjusted return.</p>
<p>If you do not have any information about the assets (or, more realistically, any reliable information) you can assign the same weight to each asset: this maximizes the entropy (a measure of diversity) of the weights.</p>
<pre class="r"><code>plot_portfolio &lt;- function(w, label, V, mu) {

  require(quadprog)
  n &lt;- length(mu)
  A &lt;- cbind( # Each column is a constraint
    matrix( rep(1,n), nr=n ),
    diag(n)
  )
  b &lt;- c(1, rep(0,n))
  f &lt;- function(u) {
    solve.QP(Dmat = u * V, dvec = mu, Amat = A, bvec = b, meq = 1)$solution
  }
  require(parallel) # Run the computations in parallel
  risk_aversions &lt;- seq(.1, 100, length=ceiling(1e5/length(mu)))
  efw &lt;- mclapply(risk_aversions, f)
  efw &lt;- do.call(cbind, efw)
  x &lt;- sqrt( colSums(efw * (V %*% efw)) )
  y &lt;- t(efw) %*% mu
  
  # Efficient frontier points
  ef &lt;- data.frame(x=x, y=y)
  
  rd &lt;- data.frame(mu=mu, sigma=sqrt(diag(V)))
  rd$assets &lt;- row.names(rd)
  
  port_risk &lt;- sqrt( t(w) %*% V %*% w )
  port_return &lt;- t(w) %*% mu
  
  gg &lt;- ggplot(rd, aes(x = sigma, y = mu, color = assets)) +
    geom_point(size = 2) +
    ylab(&quot;Expected Return&quot;) +
    xlab(&quot;Standard Deviation (Risk)&quot;) +
    xlim(0, max(sigma)) + 
    ylim(0, 1.2*max(mu)) +
    ggtitle(&quot;Expected Returns versus Risk&quot;) +
    geom_segment(data = ef, aes(x = x, xend = dplyr::lead(x), y = y, yend = dplyr::lead(y)), color=&quot;grey&quot;) + 
    geom_point(aes(x = port_risk, y = port_return), color = &quot;cornflowerblue&quot;, size = 6) +
    geom_text(aes(x = port_risk, y = port_return, label = label, color=&quot;Portfolio&quot;), 
      position = position_dodge(width = 1), vjust = 1.5,) 
  print(gg)

}

plot_portfolio(w = rep(1/length(mu), length(mu)), label = &quot;Equal weighted&quot;, V = V, mu = mu)</code></pre>
<pre><code>## Loading required package: quadprog</code></pre>
<pre><code>## Loading required package: parallel</code></pre>
<pre><code>## Warning: Removed 1 rows containing missing values (geom_segment).</code></pre>
<p><img src="/post/2019-03-25-optimization-examples_files/figure-html/frontier-1.png" width="672" /></p>
</div>
<div id="mean-variance" class="section level2">
<h2>Mean-Variance</h2>
<p>The mean-variance portfolio maximizes the risk-adjusted expected return of the portfolio.
Usually this takes the form of <span class="math inline">\(\mu - \lambda * \sigma^{2}\)</span>, where
* <span class="math inline">\(\lambda\)</span> is the risk aversion parameter as determined by the investor
* <span class="math inline">\(\mu\)</span> is the expected return (probably proxied by the historical return)
* <span class="math inline">\(\sigma^{2}\)</span> is the risk measure, but other choices are available</p>
<p>We will use the <em>solve.QP</em> function in library quadprog, which requires converting the problem to the following format:</p>
<p>Functin call: solve.QP(Dmat, dvec, Amat, bvec, meq=0)
Find w
to maximize dvecâ€™ w - 1/2 wâ€™ Dmat w
such that Amatâ€™ q &gt;= bvec (the first meq constraints are equalities)</p>
</div>
<div id="no-constraints" class="section level2">
<h2>No constraints</h2>
<pre class="r"><code>n &lt;- length(mu)
Amat &lt;- matrix(nr = n, nc = 0)
bvec &lt;- c()
r &lt;- solve.QP(Dmat = V, dvec = mu, Amat, bvec, meq = 0)
round(r$solution, 4)</code></pre>
<pre><code>## [1] -10.0612   9.0175  -3.5802  -0.3412  -3.0118  12.5882</code></pre>
<p>With absolutely no constraints the weights no not sum to one, rather summing to â€™r sum(r$solution)`, the positions are highly levered, and there are many negative weights, implying shorting. We will now add a constraint to requie that the weights sum to one by using the Amat, bvec, and meq parameters as follows: <span class="math inline">\(Amat&#39; q &gt;= bvec\)</span>
We can create equality constraints, but they must be the first meq constraints and the remaining constraints will be inequality constraints. For long only we will only have one constraint, and that is that all the weights sum to exactly one.</p>
<pre class="r"><code>Amat &lt;- matrix(rep(1, n), nr = n)
bvec &lt;- 1
print(Amat)</code></pre>
<pre><code>##      [,1]
## [1,]    1
## [2,]    1
## [3,]    1
## [4,]    1
## [5,]    1
## [6,]    1</code></pre>
<pre class="r"><code>print(bvec)</code></pre>
<pre><code>## [1] 1</code></pre>
<p>As you can see, we created Amat as a column of all ones, bvec as a single 1, and set meq=1 so the function knows it is an equality constraint.</p>
<pre class="r"><code>r &lt;- solve.QP(Dmat=V, dvec=mu, Amat, bvec, meq=1)
sum(r$solution)</code></pre>
<pre><code>## [1] 1</code></pre>
<pre class="r"><code>round(r$solution, 2)</code></pre>
<pre><code>## [1] -10.19   2.36  -4.65   2.29  -0.93  12.12</code></pre>
<p>Now the weights sum to one, but the leverage is still too high. Lets modify Amat and bvec as follows:</p>
<pre class="r"><code>Amat &lt;- cbind(matrix( rep(1,n), nr=n ), diag(n))
bvec &lt;- c(1, rep(0,n))
print(Amat)</code></pre>
<pre><code>##      [,1] [,2] [,3] [,4] [,5] [,6] [,7]
## [1,]    1    1    0    0    0    0    0
## [2,]    1    0    1    0    0    0    0
## [3,]    1    0    0    1    0    0    0
## [4,]    1    0    0    0    1    0    0
## [5,]    1    0    0    0    0    1    0
## [6,]    1    0    0    0    0    0    1</code></pre>
<pre class="r"><code>print(bvec)</code></pre>
<pre><code>## [1] 1 0 0 0 0 0 0</code></pre>
<p>This make this concept concrete, here is how the matrix would look in equation form:</p>
<pre class="r"><code>eq &lt;- c(&quot;=&quot;, rep(&quot;&gt;=&quot;, n))
print(rbind(Amat, eq, bvec))</code></pre>
<pre><code>##      [,1] [,2] [,3] [,4] [,5] [,6] [,7]
##      &quot;1&quot;  &quot;1&quot;  &quot;0&quot;  &quot;0&quot;  &quot;0&quot;  &quot;0&quot;  &quot;0&quot; 
##      &quot;1&quot;  &quot;0&quot;  &quot;1&quot;  &quot;0&quot;  &quot;0&quot;  &quot;0&quot;  &quot;0&quot; 
##      &quot;1&quot;  &quot;0&quot;  &quot;0&quot;  &quot;1&quot;  &quot;0&quot;  &quot;0&quot;  &quot;0&quot; 
##      &quot;1&quot;  &quot;0&quot;  &quot;0&quot;  &quot;0&quot;  &quot;1&quot;  &quot;0&quot;  &quot;0&quot; 
##      &quot;1&quot;  &quot;0&quot;  &quot;0&quot;  &quot;0&quot;  &quot;0&quot;  &quot;1&quot;  &quot;0&quot; 
##      &quot;1&quot;  &quot;0&quot;  &quot;0&quot;  &quot;0&quot;  &quot;0&quot;  &quot;0&quot;  &quot;1&quot; 
## eq   &quot;=&quot;  &quot;&gt;=&quot; &quot;&gt;=&quot; &quot;&gt;=&quot; &quot;&gt;=&quot; &quot;&gt;=&quot; &quot;&gt;=&quot;
## bvec &quot;1&quot;  &quot;0&quot;  &quot;0&quot;  &quot;0&quot;  &quot;0&quot;  &quot;0&quot;  &quot;0&quot;</code></pre>
<p>We can move along the efficient frontier (the grey line) by adjusting the risk-aversion parameter <span class="math inline">\(\lambda\)</span>. <span class="math inline">\(\lambda\)</span>=1 gives a balance between expected return and risk, whereas <span class="math inline">\(\lambda\)</span> &lt; 1 will shift the optimal portfolio to the right and <span class="math inline">\(\lambda\)</span> &gt; 1 will shift the optimal portfolio to the left.</p>
</div>
<div id="lambda-1-risk-averse-investor" class="section level2">
<h2><span class="math inline">\(\lambda\)</span> = 1: Risk-averse investor</h2>
<pre class="r"><code>r &lt;- solve.QP(Dmat=V, dvec=mu, Amat, bvec, meq=1)
sum(r$solution)</code></pre>
<pre><code>## [1] 1</code></pre>
<pre class="r"><code>round(r$solution, 2)</code></pre>
<pre><code>## [1] 0 0 0 0 1 0</code></pre>
<pre class="r"><code>plot_portfolio(w=r$solution, label=&quot;lambda = 1&quot;, V, mu)</code></pre>
<pre><code>## Warning: Removed 1 rows containing missing values (geom_segment).</code></pre>
<p><img src="/post/2019-03-25-optimization-examples_files/figure-html/longonly-1.png" width="672" /></p>
<p><span class="math inline">\(\lambda\)</span> &lt; 1 downplays the risk component and gives more importance to expected return, thus shifting the optimal portfolio to the right along the efficient frontier.</p>
</div>
<div id="lambda-1-more-risk-tolerant-investor" class="section level2">
<h2><span class="math inline">\(\lambda\)</span> &lt; 1: More risk-tolerant investor</h2>
<pre class="r"><code>r5 &lt;- solve.QP(Dmat = .5 * V, dvec = mu, Amat, bvec, meq = 1)
r1 &lt;- solve.QP(Dmat = .1 * V, dvec = mu, Amat, bvec, meq = 1)
plot_portfolio(w=r5$solution, label=&quot;lambda = .5&quot;, V, mu)</code></pre>
<pre><code>## Warning: Removed 1 rows containing missing values (geom_segment).</code></pre>
<pre class="r"><code>plot_portfolio(w=r1$solution, label=&quot;lambda = .1&quot;, V, mu)</code></pre>
<pre><code>## Warning: Removed 1 rows containing missing values (geom_segment).</code></pre>
<p><img src="/post/2019-03-25-optimization-examples_files/figure-html/riskTolerant-1.png" width="50%" /><img src="/post/2019-03-25-optimization-examples_files/figure-html/riskTolerant-2.png" width="50%" /></p>
<p><span class="math inline">\(\lambda\)</span> &gt; 1 increases the importance of the risk component and while keeping the expected returns the same, thus shifting the optimal portfolio to the left along the efficient frontier.</p>
</div>
</div>
<div id="lambda-1-more-risk-averse-investor" class="section level1">
<h1><span class="math inline">\(\lambda\)</span> &gt; 1: More risk-averse investor</h1>
<pre class="r"><code>r3 &lt;- solve.QP(Dmat = 3 * V, dvec = mu, Amat, bvec, meq = 1)
r10 &lt;- solve.QP(Dmat = 10 * V, dvec = mu, Amat, bvec, meq = 1)
plot_portfolio(w=r3$solution, label = &quot;lambda = 3&quot;, V, mu)</code></pre>
<pre><code>## Warning: Removed 1 rows containing missing values (geom_segment).</code></pre>
<pre class="r"><code>plot_portfolio(w=r10$solution, label = &quot;lambda = 10&quot;, V, mu)</code></pre>
<pre><code>## Warning: Removed 1 rows containing missing values (geom_segment).</code></pre>
<p><img src="/post/2019-03-25-optimization-examples_files/figure-html/riskAverse1-1.png" width="50%" /><img src="/post/2019-03-25-optimization-examples_files/figure-html/riskAverse1-2.png" width="50%" /></p>
</div>
<div id="minimum-volatilty-minv-vol" class="section level1">
<h1>Minimum Volatilty (Minv-Vol)</h1>
<p>The minimum volatility portfolio is achieved by setting <span class="math inline">\(\mu\)</span> to zero and solving the same optimization problem, so the optimizer finds the portfolio with the lowest risk regardless of the expected return. The minimum volatility portfolio is on the left and the mean variance portfolio is on the right for comparison purposes.</p>
<pre class="r"><code>r0 &lt;- solve.QP(Dmat = V, dvec = 0 * mu, Amat, bvec, meq = 1)
r &lt;- solve.QP(Dmat = V, dvec = mu, Amat, bvec, meq = 1)
plot_portfolio(w=r0$solution, label = &quot;Minv-Vol&quot;, V, mu)</code></pre>
<pre><code>## Warning: Removed 1 rows containing missing values (geom_segment).</code></pre>
<pre class="r"><code>plot_portfolio(w=r$solution, label = &quot;Mean-Variance vol&quot;, V, mu)</code></pre>
<pre><code>## Warning: Removed 1 rows containing missing values (geom_segment).</code></pre>
<p><img src="/post/2019-03-25-optimization-examples_files/figure-html/riskAverse-1.png" width="50%" /><img src="/post/2019-03-25-optimization-examples_files/figure-html/riskAverse-2.png" width="50%" /></p>
<p>We hope this helps you understand the basics of efficient frontiers and portfolio optimization, and gives you a starting point to optimizing portfolios in R.</p>
</div>
